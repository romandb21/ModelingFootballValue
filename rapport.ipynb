{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u>**Modélisation statistique de la valeur des joueurs de football à partir de leurs performances.**</u>\n",
    "\n",
    "Par Roman Dupraz-Bardou, Lenny Ouakil et Paul Lemoine Vandermoere\n",
    "\n",
    "## <u>**Introduction :**</u>\n",
    "\n",
    "L’évaluation de la valeur des joueurs est une composante clé dans le football moderne. Cette valeur, que l'on peut définir comme une estimation monétaire de ce qu'un club pourrait payer pour acquérir un joueur sur le marché des transferts, reflète l’évaluation de plusieurs facteurs liés aux performances du joueur, à ses caractéristiques, à son contrat avec son club... Elle n’est pas un montant fixe, mais une estimation qui peut varier en fonction des observateurs. Des plateformes comme Transfermarkt et le CIES fournissent des estimations, mais les clubs cherchent souvent à obtenir des informations plus précises basées sur des performances actualisées. Ce projet vise à construire un modèle qui estime la valeur des joueurs à partir de diverses sources de données sur les performances (open data, scraping, API), puis à comparer les estimations avec celles des plateformes publiques comme Transfermarkt ou le CIES. Pour cela, nous nous concentrerons sur les sept grands championnats européens (Premier League, Ligue 1, Bundesliga, Liga, Serie A, Eredivisie, Liga Portugal) de 2015 à 2024 (championnats écourtés pour cause de pandémie du covid19).\n",
    "\n",
    "Ainsi, nous nous attendons à observer une corrélation positive entre les performances des joueurs (nombre de buts, de passes décisives, taux de clean sheet...) et leur valeur. Afin d'obtenir un nombre conséquent de données nécessaires à la construction de ce modèle, nous utiliserons des API comme Footballdata.org qui offrent des statistiques détaillées sur les performances des joueurs des sept grands championnats européens (xG, passes clés, interceptions, dribbles, etc.), du scraping depuis des plateformes comme Transfermarkt pour récupérer les valeurs marchandes publiques des joueurs. Il pourrait aussi être intéressant d'intégrer des variables démographiques et/ou caractéristiques (âge, position, durée du contrat) depuis des sources telles que Transfermarkt ou d'autres bases de données disponibles en open data. \n",
    "\n",
    "### <u> Sommaire</u>\n",
    "\n",
    "1. [Installation](#installation)\n",
    "2. [Obtention des données](#obtention-des-données)\n",
    "   - [Utilisation d'API](#utilisation-d'api)\n",
    "   - [Scraping des données de valeur marchande](#scraping-des-données-de-valeur-marchande)\n",
    "   - [Scraping des données de performances depuis FBref](#scraping-depuis-fbref)\n",
    "   - [Cartographie](#cartographie)\n",
    "3. [Statistiques descriptives](#statistiques-descriptives)\n",
    "4. [Modèle de prédiction](#modèle-de-prédiction)\n",
    "5. [Conclusion](#conclusion)\n",
    "\n",
    "\n",
    "<a id='installation'></a>\n",
    "## <u>**1. Installation** </u>\n",
    "\n",
    "Afin de construire ce projet, nous avons eu besoin de différentes librairies : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "import webbrowser\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as path_effects\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "import io\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='obtention-des-données'></a>\n",
    "## <u>2. Obtention des données</u>\n",
    "\n",
    "<a id='utilisation-d'api'></a>\n",
    "### <u> Utilisation d'API </u>\n",
    "\n",
    "Dans un premier temps, il nous a paru intéressant d'utiliser des API afin de récupérer des données essentielles sur les joueurs. Il existe différentes API sur le sujet, mais pour des raisons d'efficacité, nous nous focaliserons sur celle fournie par Footballdata.org, dont le plan gratuit permet d'extraire davantage d'informations. Avec cette API, nous avons accès aux informations élémentaires sur les équipes de 10 championnats : Champions League, Primeira Liga, Premier League, Championship, Ligue 1, Eredivisie, Bundesliga, Serie A, Liga ainsi que la Serie A brésilienne. Nous sommes aussi en mesure de fournir des données de l'Euro 2024 et de la Coupe du Monde 2022.\n",
    "\n",
    "Toutefois, nous nous concentrons ici sur les sept grands championnats européens, dont les ID sont 2021 (Premier League), 2014 (Liga), 2015 (Ligue 1), 2002 (Bundesliga), 2019 (Serie A), 2003 (Eredivisie), 2017 (Primeira Liga). Nous pouvons ainsi accéder à différentes informations sur les équipes qui composent ces championnats. Prenons le cas de la Premier League :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Api.infoapi as api\n",
    "\n",
    "api.get_teams(2021) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ainsi, grâce à ce data frame nous sommes en capacité d'observer les équipes présentes dans le championnat anglais, mais aussi leur ID. Cela nous permettra ensuite de pouvoir réaliser des recherches plus poussées sur ces équipes afin de nous concentrer sur les joueurs. Regardons plus en détail l'effectif de Manchester United, à l'aide d'un data frame ainsi que d'une représentation par poste: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Api.infoapi as api\n",
    "\n",
    "api.get_players(66) #crée le data frame de l'effectif\n",
    "api.draw_team(66) #crée une représentation de l'effectif par poste "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons ainsi pu extraire des informations essentielles sur les joueurs de Manchester United. Toutefois, le plan gratuit ne nous permet pas d'accéder à la valeur marchande des joueurs, pourtant centrale dans notre projet. Il sera donc nécessaire d'utiliser d'autres moyens pour l'obtenir. C'est ce que nous allons voir désormais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='scraping-des-données-de-valeur-marchande'></a>\n",
    "### <u>Scraping des données de valeur marchande </u>\n",
    "\n",
    "Le site web de référence en termes d'évaluation de la valeur marchande des joueurs de football est sans contestation possible [**Transfermarkt**](https://www.transfermarkt.com/). Fondé en 2000 par un passionné et supporter du Werder Brême, **Transfermarkt** a rapidement évolué pour devenir une plateforme incontournable dans l'univers du football. Il offre une multitude de données, des statistiques sur les joueurs aux informations sur les transferts, en passant par les performances sur le terrain.\n",
    "\n",
    "Ainsi, les valeurs **Transfermarkt** reflètent plus l'opinion subjective des fans du ballon rond qu'un réel estimateur objectif permettant de comparer les joueurs entre eux. Il est donc intéressant de trouver des joueurs sous-cotés par rapport à leur valeur **Transfermarkt**. C'est la stratégie suivie par de plus en plus de clubs en Europe comme le Toulouse Football Club ou Liverpool, par exemple.\n",
    "\n",
    "Malheureusement, le scrapping sur **Transfermarkt** est interdit d'après les conditions d'utilisation. Néanmoins, il semble être toléré et de nombreux utilisateurs de Kaggle scrappent le site régulièrement. Nous avons donc décidé d'utiliser un [**Kaggle**](https://www.kaggle.com/datasets/davidcariboo/player-scores/data?select=clubs.csv) scrappant chaque semaine le site **Transfermarkt** afin de limiter le trafic sur ses serveurs et de réduire ainsi notre responsabilité. Celui-ci contient de nombreuses données essentielles pour notre projet comme les transferts et les valeurs marchandes des joueurs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_df = pd.read_csv('using_data/players.csv')\n",
    "transfers_df = pd.read_csv('using_data/transfers.csv')\n",
    "valuations_df = pd.read_csv('using_data/player_valuations.csv')\n",
    "clubs_df = pd.read_csv('using_data/clubs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois les datasets récupérés et convertis en dataframe, nous pouvons commencer les premiers traitements et analyses. Tout d'abord, nous ne conservons que les transferts pertinents, c'est-à-dire :\n",
    "\n",
    "- Les transferts avec une valeur de transfert supérieure à 100 000 euros (afin de ne pas prendre en compte les prêts, les fins de contrats ou tout autre transfert non conventionnel).\n",
    "- Les transferts impliquant des joueurs des sept ligues européennes majeures (Allemagne, Angleterre, Espagne, France, Italie, Pays-Bas et Portugal).\n",
    "- Les transferts effectués lors des 10 dernières saisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import using_data.getkaggledata as gkd\n",
    "\n",
    "relevant_transfers = gkd.filter_relevant_transfers(transfers_df)\n",
    "top_clubs = gkd.filter_top_clubs(clubs_df)\n",
    "relevant_transfers = gkd.merge_transfers_with_clubs(relevant_transfers, top_clubs)\n",
    "relevant_transfers.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois cela fait, il peut être intéressant d'analyser les liens entre les valeurs de transferts (variable 'transfer_fee') et les valeurs marchandes (variable 'market_value_in_eur')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gkd.analyze_value_discrepancy(relevant_transfers, 'transfer_fee', 'market_value_in_eur')\n",
    "\n",
    "gkd.compute_correlations(relevant_transfers['transfer_fee'], relevant_transfers['market_value_in_eur'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les résultats montrent une forte corrélation positive entre les valeurs des transferts et les valeurs marchandes des joueurs, avec un coefficient de corrélation de Pearson de 0.86 et un coefficient de corrélation de Spearman de 0.84. Cela indique que les valeurs de transfert augmentent généralement de manière proportionnelle aux valeurs marchandes, et cette relation est à la fois linéaire et monotone. De plus, la différence moyenne d'environ 1 million d'euros entre les valeurs de transfert et les valeurs marchandes suggère une tendance systématique dans les évaluations des joueurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gkd.analyze_club_metrics(relevant_transfers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le graphique montre que la majorité des clubs ont une forte corrélation (plus de 0.8) entre les valeurs de transfert sur Transfermarkt et les valeurs de transfert réelles, que ce soit lorsqu'ils vendent ou achètent des joueurs. Cela indique que, pour la plupart des clubs, les valeurs de transfert sur Transfermarkt sont un bon indicateur des valeurs de transfert réelles.\n",
    "\n",
    "Des clubs comme le RC Lens et Swansea suivent de très près les valeurs de Transfermarkt lors de leurs transactions, avec des corrélations proches de 1. Cela signifie que les valeurs de transfert de ces clubs sont presque parfaitement alignées avec les évaluations de Transfermarkt, tant pour les ventes que pour les achats.\n",
    "\n",
    "En revanche, certains clubs comme Levante montrent des transactions très décorrélées avec les valeurs de Transfermarkt. Cela pourrait indiquer que Levante utilise des critères différents ou des stratégies spécifiques qui ne sont pas reflétés dans les évaluations de Transfermarkt.\n",
    "\n",
    "Enfin, un club comme le PEC Zwolle va à l'encontre des tendances de Transfermarkt lorsqu'il achète des joueurs, avec une corrélation de Pearson en tant qu'acheteur de -0.6. Cela suggère que PEC Zwolle pourrait acheter des joueurs à des valeurs significativement différentes de celles estimées par Transfermarkt, peut-être en raison d'une tendance à flairer les 'bons coups' sur le marché des transferts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='scraping-depuis-fbref'></a>\n",
    "### <u> Scraping des données de performances depuis FBref </u>\n",
    "\n",
    "Dans le but de diversifier nos sources de données sur les joueurs, nous nous sommes aussi concentré sur le scraping des tableaux de données présents dans le site [FBref.com](https://fbref.com/en/). FBref est un site spécialisé dans les statistiques et les analyses détaillées de football et offre des données complètes sur les joueurs, les équipes et les compétitions du monde entier. Comme précisé précédemment, nous nous sommes accordés pour restreindre l'étude sur les 7 grands championnats européens (pour rappel : English Premier League , Spanish LaLiga, French Ligue 1, German Bundesliga, Italian Serie A, Dutch Eredivisie, Portuguese Primeira Liga). Le but est de récupérer tous les joueurs ayant joué dans un des 7 championnats au moins une saison durant les 10 dernières saisons (de 2015-2016 à 2024-2025) et de scraper leurs statistiques au moins depuis 2010-2011. Nous scraperons d'abord les joueurs d'Eredivisie puis de Primeira Liga et enfin le top5 en une seule fois.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expliquons d'abord le procédé pour le scraping des joueurs d'Eredivisie. \n",
    "Nous commençons par coder une fonction qui nous donne tous les urls des clubs présents dans la ligue à une saison donnée. Pour cela, il faut accéder à la table qui contient tous les clubs de la ligue à une saison donnée dont l'id est 'results{season}231_overall' et récupérer l'url de chaque club présent dans la table : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_club_urls(league_url, season):\n",
    "    '''Get URLs for all clubs in the league for a specific season'''\n",
    "    HEADERS = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "    response = requests.get(league_url, headers=HEADERS)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Replace dynamic ID based on the season\n",
    "    table_id = f'results{season}231_overall'\n",
    "    clubs_table = soup.find('table', id=table_id)\n",
    "    \n",
    "    if not clubs_table:\n",
    "        raise ValueError(f'Could not find the clubs table with ID: {table_id}')\n",
    "\n",
    "    club_links = []\n",
    "    for row in clubs_table.find_all('tr'):\n",
    "        first_col = row.find('td', {'data-stat': 'team'})\n",
    "        if first_col and first_col.find('a'):\n",
    "            link0 = 'https://fbref.com' + first_col.find('a')['href']\n",
    "            club_links.append(link0)\n",
    "    \n",
    "    return club_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le dictionnaire HEADERS est utilisé pour définir des en-têtes HTTP personnalisés lors de la requête effectuée avec requests.get. Ces en-têtes sont principalement utiles pour éviter d'être bloqué par le serveur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_club_urls('https://fbref.com/en/comps/23/2023-2024/2023-2024-Eredivisie-Stats', '2023-2024')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite il faut une fonction qui renvoie pour chaque club la liste d'url de chaque joueurs. On récupère la table de joueurs d'id 'stats_standard_23' et on construit les liens pour avoir la page des joueurs sur toutes les compétitions confondues: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_club_players(club_url):\n",
    "    '''Get player links for a specific club'''\n",
    "    HEADERS = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "    time.sleep(random.uniform(3, 4))  # random delay\n",
    "    \n",
    "    response = requests.get(club_url, headers=HEADERS)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    players_table = soup.find('table', id='stats_standard_23')\n",
    "    \n",
    "    if not players_table:\n",
    "        print(f'Warning: no players table for {club_url} ')\n",
    "        return []\n",
    "\n",
    "    player_links = []\n",
    "    for row in players_table.find_all('tr'):\n",
    "        player_cell = row.find('th', {'data-stat': 'player'})\n",
    "        if player_cell and player_cell.find('a'):\n",
    "            player_link = player_cell.find('a')['href']\n",
    "            \n",
    "            # Build complete URL\n",
    "            linkbefore = 'https://fbref.com' + player_link\n",
    "            linkmid = linkbefore.split('/')\n",
    "            linkmid.insert(6, 'all_comps')\n",
    "            full_url = '/'.join(linkmid) + '-Stats---All-Competitions'\n",
    "            \n",
    "            player_links.append(full_url)\n",
    "    \n",
    "    return player_links\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise une pause random entre 3 et 4 secondes de pause de manière random pour que le serveur ait plus de mal à détecter le fait que le scraping est automatisé. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_club_players('https://fbref.com/en/squads/e334d850/2023-2024/PSV-Eindhoven-Stats')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et maintenant il nous faut une fonction qui, pour chaque joueur d'un club entré en argument, récupère la table de données pour toutes les saisons plus récentes que 2010-2011. \n",
    "Cependant la table du site est une table dont les colonnes sont multiindexées : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with Luuk de Jong's table\n",
    "\n",
    "# Get Luuk de Jong's table and convert it into a DataFrame to inspect its columns\n",
    "HEADERS = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "response = requests.get('https://fbref.com/en/players/abb3bb95/Luuk-de-Jong', headers=HEADERS)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "stats_table = soup.find('table', id='stats_standard_dom_lg')\n",
    "stats_table_html = str(stats_table)\n",
    "stats_table = pd.read_html(io.StringIO(stats_table_html), header=[0, 1])[0]\n",
    "\n",
    "\n",
    "print(stats_table.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il faut alors créer une fonction qui aplatit les colonnes tout en les renommant de manière à ce que le nom de la colonne de l'index le plus haut soit suivi de ' : ' et du nom de la colonne du deuxième index (lorsque le premier index commence par 'Unnamed' , on choisi de garder seulement le nom du deuxième index). Pour donner un exemple : la colonne ('Performance','Gls') devient 'Performance : Gls' et \n",
    "('Unnamed: 0_level_0', 'Season') devient 'Season'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns(df):\n",
    "    new_columns = []\n",
    "    for col in df.columns:\n",
    "        # If the 1st index starts with 'Unnamed', the column takes the name of the 2nd index\n",
    "        if str(col[0]).startswith('Unnamed'):\n",
    "            new_columns.append(col[1])\n",
    "        else: # The names of the 1st and 2nd index are combined with ':'\n",
    "            new_columns.append(f'{col[0]} : {col[1]}')\n",
    "    \n",
    "    # Apply the new column names\n",
    "    df.columns = new_columns\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with Luuk de Jong's table\n",
    "print(rename_columns(stats_table).columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut maintenant coder une fonction qui récupère la table du joueur entre 2010-2011 et 2024-2025. \n",
    "Sur le FBref, la table à un id qui est égal à 'stats_standard_expanded' ou 'stats_standard_dom_lg' selon les joueurs. On la récupère, on rajoute une colonne 'Player' qui donne le nom du joueur et on applique la fonction précédente pour reshape le dataframe obtenu. \n",
    "De plus, pour optimiser notre scraping en temps et en espace, nous avons rajouté un argument 'existing_players' à la fonction  pour ne pas scraper la table d'un joueur si le joueur est déjà dans la liste existing_players. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_stats_player(player_url, existing_players):\n",
    "    '''Get statistics for a specific player if not already in the dataset.'''\n",
    "\n",
    "    # Get player name and check if it is on the existing_players list\n",
    "    player_name = player_url.split('/')[-1].replace('-Stats---All-Competitions', '').replace('-', ' ')\n",
    "\n",
    "    if player_name in existing_players:\n",
    "        print(f'Skipping {player_name} (already exists in the dataset).')\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    HEADERS = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "    time.sleep(random.uniform(3, 4)) # random delay\n",
    "\n",
    "    # Get the stats table \n",
    "    try:\n",
    "        response = requests.get(player_url, headers=HEADERS)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        stats_table = soup.find('table', id='stats_standard_expanded')\n",
    "        \n",
    "        if stats_table is None:\n",
    "            stats_table = soup.find('table', id='stats_standard_dom_lg')\n",
    "            \n",
    "        if stats_table is None:\n",
    "            print(f'No stats table found for URL: {player_url}')\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # Convert HTML table into DataFrame\n",
    "        try:\n",
    "            stats_table_html = str(stats_table)  # Convertir en chaîne\n",
    "            stats_table = pd.read_html(io.StringIO(stats_table_html), header=[0, 1])[0]\n",
    "        except ValueError as e:\n",
    "            print(f'Error reading HTML table for {player_name}: {e}')\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # Create a copy to avoid SettingWithCopyWarning\n",
    "        stats_table = stats_table.copy()\n",
    "\n",
    "        # add the player's name\n",
    "        stats_table.loc[:, ('Unnamed: -1_level_0', 'Player')] = player_name\n",
    "\n",
    "        # Reorder columns \n",
    "        new_order = [('Unnamed: -1_level_0', 'Player')] + list(stats_table.columns[:-1])\n",
    "        stats_table = stats_table[new_order]\n",
    "\n",
    "        # Renaming and flattening columns \n",
    "        stats_table = rename_columns(stats_table)\n",
    "\n",
    "        # Keep only season since 2010-2011\n",
    "        allowed_seasons = ['2010-2011', '2011-2012', '2012-2013', '2013-2014','2014-2015', '2015-2016', '2016-2017', '2017-2018', '2018-2019', '2019-2020', '2020-2021', '2021-2022', \n",
    "            '2022-2023', '2023-2024', '2024-2025']\n",
    "        season_column = 'Season'\n",
    "        if season_column in stats_table.columns:\n",
    "            stats_table = stats_table[stats_table[season_column].isin(allowed_seasons)]\n",
    "\n",
    "        return stats_table\n",
    "    except Exception as e:\n",
    "        print(f'Error scraping stats for {player_name}: {e}')\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_stats_player('https://fbref.com/en/players/abb3bb95/Luuk-de-Jong', []).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_stats_player('https://fbref.com/en/players/abb3bb95/Luuk-de-Jong', ['Luuk de Jong'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reste maintenant à coder une fonction pour appliquer scrape_stats_player fonctions à tous les joueurs des tous les clubs qui ont joué en Eredivisie entre 2015-2016 et 2024-2025. On met en place un système de suivi de progression dans un fichier JSON qui nous permet de reprendre la boucle à un endroit précis si besoin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_FILE = 'scraping_progress_ered.json'\n",
    "\n",
    "def save_progress(data):\n",
    "    '''Save scraping progress to a JSON file, including the season.'''\n",
    "    with open(CONFIG_FILE, 'w') as f:\n",
    "        json.dump(data, f)\n",
    "\n",
    "        \n",
    "\n",
    "def load_progress():\n",
    "    '''Load previous scraping progress.'''\n",
    "    try:\n",
    "        with open(CONFIG_FILE, 'r') as f:\n",
    "            return json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        return {'season': None, 'last_club': None, 'last_player': None}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_resumption_points(progress, season, club_urls, club_url=None, player_urls=None):\n",
    "    '''\n",
    "    Determine resumption points for season, club, and player based on progress.\n",
    "    Returns a tuple: start_club_index, start_player_index\n",
    "    '''\n",
    "    # Find starting club index\n",
    "    start_club_index = 0\n",
    "    if progress['season'] == season and progress['last_club']:\n",
    "        normalized_last_club = progress['last_club'].split('/squads/')[1].split('/')[0]\n",
    "        for i, url in enumerate(club_urls):\n",
    "            if f'/squads/{normalized_last_club}/' in url:\n",
    "                start_club_index = i\n",
    "                break\n",
    "\n",
    "    # Find starting player index if applicable\n",
    "    start_player_index = 0\n",
    "    if player_urls and progress['season'] == season and progress['last_club'] == club_url and progress['last_player']:\n",
    "        try:\n",
    "            start_player_index = player_urls.index(progress['last_player'])\n",
    "        except ValueError:\n",
    "            start_player_index = 0\n",
    "\n",
    "    return start_club_index, start_player_index\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main(season, all_players_stats, existing_players):\n",
    "    '''\n",
    "    Main function to scrape stats for a specific season, resuming from saved progress.\n",
    "    '''\n",
    "    ered_url = f'https://fbref.com/en/comps/23/{season}/{season}-Eredivisie-Stats'\n",
    "    progress = load_progress()\n",
    "\n",
    "    # Update season if necessary\n",
    "    if progress.get('season') != season:\n",
    "        progress = {'season': season, 'last_club': None, 'last_player': None}\n",
    "        save_progress(progress)\n",
    "\n",
    "    # Get club URLs\n",
    "    club_urls = get_club_urls(ered_url, season)\n",
    "    all_players_stats = pd.DataFrame()\n",
    "\n",
    "    # Identify resumption point for clubs\n",
    "    start_club_index, _ = get_resumption_points(progress, season, club_urls)\n",
    "\n",
    "    # Process each club starting from the resumption index\n",
    "    for club_url in club_urls[start_club_index:]:\n",
    "        try:\n",
    "            print(f'Scraping club: {club_url}')\n",
    "            player_urls = scrape_club_players(club_url)\n",
    "\n",
    "            # Identify resumption point for players\n",
    "            _, start_player_index = get_resumption_points(progress, season, club_urls, club_url, player_urls)\n",
    "\n",
    "            # Scrape stats for each player starting from the resumption index\n",
    "            for player_url in player_urls[start_player_index:]:\n",
    "                print(f'Scraping player: {player_url}')\n",
    "                player_stats = scrape_stats_player(player_url, existing_players)\n",
    "\n",
    "                # Append stats to the main DataFrame\n",
    "                if not player_stats.empty:\n",
    "                    all_players_stats = pd.concat([all_players_stats, player_stats], ignore_index=True)\n",
    "\n",
    "                # Save progress after each player\n",
    "                save_progress({'season': season, 'last_club': club_url, 'last_player': player_url})\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f'Error for club {club_url}: {e}')\n",
    "\n",
    "    print('Scraping terminé.')\n",
    "    if os.path.exists(CONFIG_FILE):\n",
    "        os.remove(CONFIG_FILE)\n",
    "\n",
    "    return all_players_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin, il nous reste à créer une fonction qui prend en entrée seulement une saison donnée et enregistre le résultat dans un fichier csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_with_existing_data(season):\n",
    "    # Load existing data\n",
    "    # Get the directory of the current script\n",
    "    script_dir = os.getcwd()\n",
    "    # Dynamically construct the path to 'results_csv' in the parent directory\n",
    "    scraping_data_dir = os.path.join(script_dir, 'scraping_data')\n",
    "    results_dir = os.path.join(scraping_data_dir, 'results_csv')\n",
    "    # Construct the full path to the CSV file\n",
    "    file_path = os.path.join(results_dir, 'players_stats_eredivisie.csv')\n",
    "\n",
    "    # Check if the file exists\n",
    "    if not os.path.exists(file_path):\n",
    "        # If the file doesn't exist, create an empty DataFrame and save it as the CSV\n",
    "        print(f'{file_path} does not exist. Creating a new empty file.')\n",
    "        empty_df = pd.DataFrame()  # Create an empty DataFrame\n",
    "        empty_df.to_csv(file_path, index=False)  # Save it as a CSV file\n",
    "\n",
    "    # Load existing data\n",
    "    try:\n",
    "        existing_data = pd.read_csv(file_path, low_memory=False)\n",
    "        existing_players = set(existing_data['Player'].unique())\n",
    "    except FileNotFoundError:\n",
    "        existing_data = pd.DataFrame()\n",
    "        existing_players = set()\n",
    "\n",
    "    # Initialize all_players_stats with existing data\n",
    "    all_players_stats = existing_data\n",
    "\n",
    "    # Scrape new data for the given season\n",
    "    all_players_stats = main(season, all_players_stats, existing_players)\n",
    "\n",
    "    # Remove duplicates (if necessary)\n",
    "    if all_players_stats.duplicated(subset=['Player', 'Season']).any():\n",
    "        all_players_stats = all_players_stats.drop_duplicates(subset=['Player', 'Season'])\n",
    "\n",
    "    # Save the updated dataset back to the original file\n",
    "    all_players_stats.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et voila, notre fonction est prête à scraper! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''seasons_list=['2015-2016', '2016-2017', '2017-2018', '2018-2019', '2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
    "for season in seasons_list:\n",
    "    main_with_existing_data(season)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les ''' ''' ont été rajoutées puisque le code tourne pendant longtemps et ce n'est pas nécessaire de le faire fonctionner pour la suite puisque les csv sont déjà disponibles dans le git. D'ailleurs voici un aperçu de 'players_stats_eredivisie.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_dir = os.getcwd()\n",
    "scraping_data_dir = os.path.join(script_dir, 'scraping_data')\n",
    "results_dir = os.path.join(scraping_data_dir, 'results_csv')\n",
    "file_path = os.path.join(results_dir, 'players_stats_eredivisie.csv')\n",
    "\n",
    "\n",
    "print(file_path)\n",
    "df = pd.read_csv(file_path, low_memory=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On fait exactement la même chose avec quelques légers changements pour la Primeira Liga : \n",
    "- dans get_club_urls : table_id = f'results{season}321_overall' \n",
    "- dans scrape_club_players : players_table = soup.find('table', id='stats_standard_32')\n",
    "- dans main : primeira_url = f'https://fbref.com/en/comps/32/{season}/{season}-Primeira-Liga-Stats'\n",
    "- dans main_with_existing_data : file_path = os.path.join(results_dir, 'players_stats_primeiraliga.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De même pour scraper les données des 5 grands championnats :\n",
    "- dans get_club_urls : clubs_table = soup.find('table', id='big5_table')\n",
    "- dans scrape_club_players : 'players_table = soup.find('table', id='stats_standard_23')' devient \n",
    "    'for x in [20, 13, 12, 9, 11]:\n",
    "        if soup.find('table', id=f'stats_standard_{x}') is not None:\n",
    "            players_table = soup.find('table', id=f'stats_standard_{x}')'\n",
    "- dans main : top5_url = f'https://fbref.com/en/comps/Big5/{season}/{season}-Big-5-European-Leagues-Stats'\n",
    "- dans main_with_existing_data : file_path = os.path.join(results_dir, 'players_stats_top5.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin il nous reste à concaténer les csv en éliminant les doublons ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_dir = os.getcwd()\n",
    "scraping_data_dir = os.path.join(script_dir, 'scraping_data')\n",
    "results_dir = os.path.join(scraping_data_dir, 'results_csv')\n",
    "\n",
    "\n",
    "top5_path = os.path.join(results_dir, 'players_stats_top5.csv')\n",
    "primeira_path = os.path.join(results_dir, 'players_stats_primeiraliga.csv')\n",
    "eredivisie_path = os.path.join(results_dir, 'players_stats_eredivisie.csv')\n",
    "\n",
    "\n",
    "top5= pd.read_csv(top5_path, low_memory=False)\n",
    "primeira=pd.read_csv(primeira_path, low_memory=False)\n",
    "eredivisie=pd.read_csv(eredivisie_path, low_memory=False)\n",
    "\n",
    "\n",
    "# Keep common columns\n",
    "common_columns = primeira.columns.intersection(top5.columns)\n",
    "\n",
    "\n",
    "primeira_common = primeira[common_columns]\n",
    "eredivisie_common = eredivisie[common_columns]\n",
    "top5_common = top5[common_columns]\n",
    "\n",
    "\n",
    "# Delete duplicated columns\n",
    "primeira_common = primeira_common.loc[:, ~primeira_common.columns.duplicated()]\n",
    "eredivisie_common = eredivisie_common.loc[:, ~eredivisie_common.columns.duplicated()]\n",
    "top5_common = top5_common.loc[:, ~top5_common.columns.duplicated()]\n",
    "\n",
    "# union of the 3 dataframes into top7 dataframe\n",
    "top7= pd.concat([primeira_common, top5_common], ignore_index=True)\n",
    "top7= pd.concat([eredivisie_common, top7], ignore_index=True)\n",
    "\n",
    "# Deleting the duplicated (player, saison) and sorting by players\n",
    "top7 = top7.drop_duplicates(subset = ['Player', 'Season'])\n",
    "top7 = top7.sort_values(by = 'Player')\n",
    "\n",
    "# save into a csv\n",
    "top7.to_csv(os.path.join(results_dir, 'players_stats_top7.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut aussi donner le nombre total de joueurs et le nombre de joueurs par saison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_dir = os.getcwd()\n",
    "scraping_data_dir = os.path.join(script_dir, 'scraping_data')\n",
    "results_dir = os.path.join(scraping_data_dir, 'results_csv')\n",
    "top7_path = os.path.join(results_dir, 'players_stats_top7.csv')\n",
    "\n",
    "\n",
    "# count players \n",
    "def count_players(file_path):\n",
    "    df= pd.read_csv(file_path, low_memory=False)\n",
    "    players_per_season = df.groupby(('Season'))[('Player')].nunique()\n",
    "    players = df[('Player')].nunique()\n",
    "    return(players, players_per_season)\n",
    "\n",
    "count_players(top7_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce scraping a rencontré plusieurs difficultés majeures, principalement liées aux blocages du serveur, au temps nécessaire pour effectuer le scraping, ainsi qu’à la construction complexe et variable du site source. Tout d’abord, nous n’avons pas pu récupérer l’intégralité des données souhaitées, car le site bloquait parfois l’accès aux tables de statistiques de certains joueurs. Cela nous a contraints à relancer le code à plusieurs reprises afin de compléter les informations manquantes pour les joueurs affectés par ces interruptions. Ces blocages fréquents sont directement liés à une autre difficulté majeure : la faible vitesse de scraping. En effet, tout temps de pause inférieur à trois secondes entre les requêtes entraînait presque systématiquement un blocage de la part du serveur, rendant le processus particulièrement lent et encore plus en sachant que nous avons du relancer le code à plusieurs reprises.\n",
    "\n",
    "Par ailleurs, un autre obstacle, bien que moins critique, a été la difficulté à comprendre et à s’adapter à l’organisation du site. Par exemple, les joueurs possèdent des tables de statistiques identifiées soit par l’id stats_standard_expanded, soit par stats_standard_dom_lg, en fonction de leur participation simultanée à plusieurs compétitions. Cette variation dans la structure des données nous a obligé à mettre en place des ajustements spécifiques pour gérer ces cas de figure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cartographie'></a>\n",
    "### <u>Cartographie </u>\n",
    "\n",
    "Dans le cadre de notre projet, nous avons aussi souhaité réutiliser des méthodes que nous avions découvertes lors du cours de *Python pour la data science*. C'est pourquoi nous avons voulu créer une nouvelle carte des stades de Ligue 1 et Ligue 2, actualisée à la saison 2024/2025, en distinguant les stades appartenant à des clubs de Ligue 1 et de Ligue 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import using_data.mapping as map\n",
    "\n",
    "# URLs for different divisions\n",
    "url_list = {\n",
    "    'L1': 'http://fr.wikipedia.org/wiki/Championnat_de_France_de_football_2024-2025',\n",
    "    'L2': 'https://fr.wikipedia.org/wiki/Championnat_de_France_de_football_de_deuxi%C3%A8me_division_2024-2025',\n",
    "}\n",
    "\n",
    "# Retrieve stadiums information for Ligue 1\n",
    "stades_ligue1 = map.retrieve_all_stadium_from_league(url_list, 'L1')\n",
    "stades_ligue2 = map.retrieve_all_stadium_from_league(url_list, 'L2')\n",
    "\n",
    "stades = pd.concat([stades_ligue1, stades_ligue2])\n",
    "\n",
    "stades = stades.dropna(subset=['latitude', 'longitude'])\n",
    "stades.loc[:, ['latitude', 'longitude']] = stades.loc[\n",
    "    :, ['latitude', 'longitude']\n",
    "].astype(float)\n",
    "stadium_locations = gpd.GeoDataFrame(\n",
    "    stades, geometry=gpd.points_from_xy(stades.longitude, stades.latitude)\n",
    ")\n",
    "\n",
    "center = stadium_locations[['latitude', 'longitude']].mean().values.tolist()\n",
    "sw = stadium_locations[['latitude', 'longitude']].min().values.tolist()\n",
    "ne = stadium_locations[['latitude', 'longitude']].max().values.tolist()\n",
    "\n",
    "m = folium.Map(location=center, tiles='openstreetmap')\n",
    "\n",
    "# I can add marker one by one on the map\n",
    "for i in range(0, len(stadium_locations)):\n",
    "    row = stadium_locations.iloc[i]\n",
    "    color = 'blue' if row['division'] == 'L1' else 'green'\n",
    "    folium.Marker(\n",
    "        [stadium_locations.iloc[i]['latitude'], stadium_locations.iloc[i]['longitude']],\n",
    "        popup=stadium_locations.iloc[i]['stade'],  icon=folium.Icon(color=color)\n",
    "    ).add_to(m)\n",
    "\n",
    "m.fit_bounds([sw, ne])\n",
    "m.save('stadiums_map.html')\n",
    "webbrowser.open('stadiums_map.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette carte nous permet de visualiser les stades des clubs de Ligue 1 et Ligue 2 et donc d'obtenir des données géographiques, pouvant expliquer la richesse du club et ainsi avoir un effet sur la valeur marchande de ses joueurs. Toutefois, du fait de la difficulté à les intégrer dans nos modèles, nous ne les utiliserons pas par la suite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='statistiques-descriptives'></a>\n",
    "## <u>3. Statistiques descriptives</u>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lors de la phase de scraping, nous avons observé une surreprésentation de certaines nationalités dans les sept grands championnats européens. Cela nous conduit à explorer plus en détail la répartition exacte des nationalités au sein de ces compétitions. Bien que certaines données puissent être manquantes, cette analyse préliminaire offrira un aperçu de la diversité nationale dans ces championnats :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scraping_data.results_csv.statsdes as des \n",
    "\n",
    "top7= 'scraping_data/results_csv/players_stats_top7.csv' #data frame of all the players who played at least one season in the top 7\n",
    "des.histo_country(top7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On observe une surreprésentation des Anglais, Italiens, Espagnols, Allemands et Français dans ces championnats. Cela suggère que détenir l'une de ces cinq nationalités pourrait avoir un effet positif sur la valeur marchande, étant donné que les joueurs aux plus grandes valeurs marchandes évoluent majoritairement dans ces compétitions. Examinons maintenant cette représentation de manière plus détaillée :\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scraping_data.results_csv.statsdes as des \n",
    "\n",
    "top7= 'scraping_data/results_csv/players_stats_top7.csv' \n",
    "des.diag_country(top7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il serait ainsi pertinent d'examiner si cette surreprésentation se retrouve également parmi les transferts les plus importants des dernières années. Pour ce faire, nous allons utiliser les données que nous avons préalablement collectées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_transfers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ces premières analyses, associées à nos connaissances du football moderne, nous amènent à nous interroger sur l'évolution des montants des transferts au cours des dernières années. En effet, nous pouvons observer l'évolution suivante : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_transfers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'évolution des montants des transferts peut s'expliquer par divers facteurs. Cependant, nous souhaitons examiner si cette hausse pourrait être liée à une amélioration des performances des joueurs. Pour cela, nous allons concentrer notre analyse sur les attaquants, dont la valeur marchande est souvent plus élevée que celle des autres joueurs. Afin d'évaluer leurs performances, nous prendrons en compte le nombre de buts et de passes décisives, renseigné dans la colonne G+A : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scraping_data.results_csv.statsdes as des\n",
    "\n",
    "top7= 'scraping_data/results_csv/players_stats_top7.csv'\n",
    "des.sum_att(top7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En excluant la saison 2019/2020, arrêtée prématurément en raison de la pandémie, ainsi que la saison 2024/2025, encore en cours, nous constatons une augmentation du nombre de buts et de passes décisives dans les sept grands championnats européens. Cette tendance pourrait en partie expliquer la hausse de la valeur marchande des attaquants au cours des dernières années."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='modélisation-valeurs'></a>\n",
    "## <u>4. Modélisation des valeurs marchandes</u>\n",
    "\n",
    "Nous avons donc récupérer deux types de données. Tout d'abord, les transferts entre clubs du top 7 sur les 10 dernières saisons, soit ce que nous tentons de modéliser, la variable expliquée. Puis les informations et performances de tous les joueurs du top 7 sur les 15 dernières saisons qui seront donc nos variables explicatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de conversion\n",
    "def convert_season_format(season):\n",
    "    start, end = season.split('/')\n",
    "    return '20' + start + '-20' + end\n",
    "\n",
    "# Appliquer la conversion à la colonne transfer_season\n",
    "relevant_transfers['transfer_season'] = relevant_transfers['transfer_season'].apply(convert_season_format)\n",
    "\n",
    "# Affichage du DataFrame mis à jour\n",
    "relevant_transfers['transfer_season'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour convertir la saison en season_id\n",
    "def convert_to_season_id(season):\n",
    "    start_year = int(season[2:4])\n",
    "    end_year = int(season[7:9])\n",
    "    return start_year + end_year\n",
    "\n",
    "# Appliquer la conversion à la colonne transfer_season\n",
    "relevant_transfers['season_id'] = relevant_transfers['transfer_season'].apply(convert_to_season_id)\n",
    "\n",
    "# Affichage du DataFrame mis à jour\n",
    "print(relevant_transfers[['transfer_season', 'season_id']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "players_stats_top7_df = pd.read_csv('scraping_data/results_csv/players_stats_top7.csv')\n",
    "\n",
    "# Affichage du DataFrame mis à jour\n",
    "print(players_stats_top7_df.head(3))\n",
    "\n",
    "# Appliquer la conversion à la colonne Season pour obtenir la saison_id\n",
    "players_stats_top7_df['season_id'] = players_stats_top7_df['Season'].apply(convert_to_season_id) + 2\n",
    "\n",
    "# Affichage du DataFrame mis à jour\n",
    "print(players_stats_top7_df[['Season', 'season_id']].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assurez-vous que les colonnes de jointure ont le même type\n",
    "players_stats_top7_df['season_id'] = players_stats_top7_df['season_id'].astype(int)\n",
    "relevant_transfers['season_id'] = relevant_transfers['season_id'].astype(int)\n",
    "\n",
    "# Fusionner les DataFrames\n",
    "data = pd.merge(players_stats_top7_df, relevant_transfers, left_on=['Player', 'season_id'], right_on=['player_name', 'season_id'])\n",
    "\n",
    "# Supprimer la colonne 'player_name'\n",
    "data.drop(columns=['player_name'], inplace=True)\n",
    "\n",
    "# Affichage du DataFrame fusionné\n",
    "print(data.shape)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Statisques principales du montant des transferts:')\n",
    "mean_value = data['transfer_fee'].mean()\n",
    "print(f'Moyenne: {mean_value}')\n",
    "mean_value = data['transfer_fee'].mean()\n",
    "print(f'Moyenne: {mean_value}')\n",
    "variance_value = data['transfer_fee'].var()\n",
    "print(f'Variance: {variance_value}')\n",
    "std_dev_value = data['transfer_fee'].std()\n",
    "print(f'Écart-type: {std_dev_value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='reg-lin'></a>\n",
    "### <u>a. Premières approches : Regressions linéaires</u>\n",
    "\n",
    "Dans un premier temps, cherchons des relations linéaires simples concernant la valeur des joueurs. La régression la plus évidente à effectuer est la régression de la valeur de transfert sur la valeur transfermarkt. En effet, elle est censée estimer la valeur des joueurs, qui se doit d'être assez proche de la valeur à laquelle ils sont échangés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from using_data.ml_models import linear_regression as lr\n",
    "from using_data.ml_models import plot_regression\n",
    "\n",
    "na_count_prop = data['market_value_in_eur'].isna().sum() \n",
    "print(\"Nombre de valeurs manquantes dans la colonne 'market_value_in_eur':\")\n",
    "print(na_count_prop)\n",
    "\n",
    "X = data[['market_value_in_eur']]  # Utiliser des doubles crochets pour obtenir un DataFrame\n",
    "y = data['transfer_fee']\n",
    "\n",
    "# Lancer une régression linéaire de 'transfer_fee' en fonction de 'Age' et afficher le résultat\n",
    "result = lr(X, y)\n",
    "print(f\"Coefficients: {result['coefficients']}\")\n",
    "print(f\"Racine carré de l'erreur quadratique moyenne: {sqrt(result['mse_test'])}\")\n",
    "print(f\"R2 : {result['r2_test']}\")\n",
    "\n",
    "# Afficher le graphique de la régression\n",
    "plot_regression(X.values, y.values, result, 'market_value_in_eur', 'Transfer Fee')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La régression obtenue est plutôt intéressante. En effet, toute chose égale par ailleurs, augmenter de 1 la valeur transfermarkt d'un joueur augmente en moyenne de 0.91 la valeur de son transfert. Le modèle explique 81% de la variance dans les valeurs de transferts. Enfin, la racine de l'écart quadratique est de 8 millions, ce qui est relativement satisfaisant au vu de l'écart-type de 'transfer_fee' (16 millions).\n",
    "\n",
    "Ceci étant fait, intéressons-nous à d'autres variables. Dans un match de football, l'équipe gagnante est celle qui marque le plus de buts. Outre ce truisme, il peut donc être assez cohérent de payer plus cher les joueurs qui contribuent le plus à faire marquer leur équipe. Regardons donc la régression de 'transfer_fee' sur le nombre de buts, de passes décisives moins le nombre de penaltys par 90 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_count = data['Per 90 Minutes : G+A-PK'].isna().sum() \n",
    "print(na_count)\n",
    "\n",
    "# Comme l'on a que 5% de NA pour la colonne 'Per 90 Minutes : G+A-PK' on peut enlever ces lignes\n",
    "data = data.dropna(subset=['Per 90 Minutes : G+A-PK'])\n",
    "na_count_prop = data.isna().sum() \n",
    "\n",
    "X = data[['Per 90 Minutes : G+A-PK']]  # Utiliser des doubles crochets pour obtenir un DataFrame\n",
    "y = data['transfer_fee']\n",
    "\n",
    "# Lancer une régression linéaire de 'transfer_fee' en fonction de 'Age' et afficher le résultat\n",
    "result = lr(X, y)\n",
    "print(f\"Racine de l'erreur quadratique moyenne: {sqrt(result['mse_test'])}\")\n",
    "print(f\"R^2: {result['r2_test']}\")\n",
    "\n",
    "# Afficher le graphique de la régression\n",
    "plot_regression(X.values, y.values, result, 'Per 90 Minutes : G+A-PK', 'Transfer Fee')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Malheureusement, les résultats sont loins d'être satisfaisants. Le R2 est de seulement 2% et la racine de l'erreur quadratique moyenne est de 19 millons ce qui signifie que prédire 'transfer_fee' par sa moyenne produit moins d'erreur en moyenne.\n",
    "\n",
    "Enfin, regardons la régression de 'transfer_fee' sur l'âge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['Age']]  # Utiliser des doubles crochets pour obtenir un DataFrame\n",
    "y = data['transfer_fee']\n",
    "\n",
    "# Lancer une régression linéaire de 'transfer_fee' en fonction de 'Age' et afficher le résultat\n",
    "result = lr(X, y)\n",
    "print(f\"Racine de l'erreur quadratique moyenne: {sqrt(result['mse_test'])}\")\n",
    "print(f\"R^2 (Test): {result['r2_test']}\")\n",
    "\n",
    "# Afficher le graphique de la régression\n",
    "plot_regression(X.values, y.values, result, 'Age', 'Transfer Fee')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que ce soit avec la racine l'erreur quadratique moyenne de 19 millions, le R2 de 0,4% ou par lecture graphique, on voit bien que les résultats ne sont pas satisfaisants. Cela peut s'expliquer par le fait qu'il y ait une grande dispersion dans les valeurs de transfert, mais surtout parce que la relation entre les valeurs de transfert et l'âge n'est pas du tout linéaire. Plus un joueur est jeune, plus il a encore du potentiel et vaut donc cher. D'un autre côté, plus il est âgé, plus il est expérimenté et donc potentiellement cher, mais plus il est proche de sa retraite, ce qui peut également diminuer sa valeur.\n",
    "\n",
    "Tout cela montre, dans notre étude, les limites d'un modèle linéaire et nous pousse à utiliser un modèle plus avancé comme une forêt d'arbres décisionnels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='random-forest'></a>\n",
    "### <u>b. Approche plus poussée : Forêt d'arbres décisionnels</u>\n",
    "\n",
    "Bien que moins bien interprétable qu'une regression linéaire, l'agorithme de forêt d'arbres décisionnels est bien plus adapté pour prédire des relations non linéaires entre les varibales. Il est donc plutôt cohérent d'y avoir recours dans notre étude.\n",
    "\n",
    "Néanmoins, il faut sélectionner les variables pertinentes pour notre modélisation mais qui contiennent un nombre faible de Na, comme précedemment avec les exemples utilisant des regressions linéaires.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_count_total = data.isna().sum().to_dict()\n",
    "print(data.shape)\n",
    "print(\"Nombre de valeurs manquantes par colonne dans le DataFrame 'relevant_transfers':\")\n",
    "print(na_count_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sur 1256 lignes, certaines variables comme 'Expected : xG' contiennent 735 Na soit environ 60% des nos données. Elles ne sont donc malheureusement pas exploitable alors même qu'elles auraient pu être pertinentes. Pour les variables 'MP' et 'Matches, elles n'apportent pas plus d'informations que les trois autres variables sur le temps de jeu, on peut donc les enlever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer le nombre de valeurs manquantes par colonne\n",
    "na_count_total = data.isna().sum()\n",
    "\n",
    "# Sélectionner les colonnes dont le nombre de valeurs manquantes est inférieur à 240\n",
    "columns_to_keep = na_count_total[na_count_total < 240].index.tolist()\n",
    "columns_to_keep.remove('MP')\n",
    "columns_to_keep.remove('Matches')\n",
    "\n",
    "# Créer un nouveau DataFrame en ne conservant que les colonnes sélectionnées\n",
    "data_clean = data[columns_to_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il reste la variable 'Country'. En regardant en détails, on se rend compte que les joueurs qui ont un Na dans la variable 'Country' ne les ont que pour des saisons spécifiques. Ainsi en chercheant parmis le data frame d'origine 'players_stats_top7_df' on peut retrouver le pays de ces joueurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer les lignes où 'MP' est un NA\n",
    "mp_na_df = data_clean[data_clean['Country'].isna()]\n",
    "\n",
    "# Calculer les occurrences de la variable 'Player'\n",
    "player_occurrences = mp_na_df['Player'].value_counts()\n",
    "print(player_occurrences.head())\n",
    "\n",
    "# Pour chaque ligne filtrée, trouver les lignes correspondantes dans players_stats_top7_df\n",
    "for index, row in mp_na_df.iterrows():\n",
    "    player = row['Player']\n",
    "    countries = players_stats_top7_df[players_stats_top7_df['Player'] == player]['Country'].dropna().unique()\n",
    "    \n",
    "    # Si des pays non NA sont trouvés, remplacer la valeur NA dans mp_na_df\n",
    "    if len(countries) > 0:\n",
    "        data_clean.at[index, 'Country'] = countries[0]  # Remplacer par le premier pays trouvé\n",
    "\n",
    "# Calculer le nombre de valeurs manquantes par colonne\n",
    "na_count_total = data_clean.isna().sum().to_dict()\n",
    "print(na_count_total)\n",
    "\n",
    "#On enlève les colonnes qui sont de type 'object'\n",
    "data_clean = data_clean.select_dtypes(exclude=['object'])\n",
    "\n",
    "# On enlève les colonnes qui contiennent 'id' dans le nom\n",
    "data_clean = data_clean[[col for col in data_clean.columns if 'id' not in col]]\n",
    "\n",
    "print(data_clean.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalement, on a bien un data_frame nettoyé (sans aucun Na) sur lequel on peut appliquer notre algorithme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dernière vérification s'il y a des valeurs non numériques\n",
    "print(data_clean.applymap(lambda x: isinstance(x, (int, float))).all().to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous utilisons le model RandomForestRegressor de la bibliothèque sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from using_data.ml_models import random_forest_regression as rfr\n",
    "from using_data.ml_models import plot_rf_feature_importances as rfi\n",
    "\n",
    "results = rfr(data_clean.drop('transfer_fee', axis = 1), data_clean['transfer_fee'] , n_estimators= 1000)\n",
    "print(\"La racine de l'erreur quadratique moyenne est : \" + str(sqrt(results['mse_test'])))\n",
    "print('Le r2 est de : ' + str(results['r2_test']))\n",
    "rfi(results['feature_importances'], results['feature_names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le coefficient de R2 indique que le modèle explique environ 76% de la variance de la variable cible, ce qui suggère que le modèle capture bien les tendances générales des données. Cependant, la racine de l'erreur quadratique moyenne (REQM) est de 9,7 millions d'euros, ce qui est relativement élevé, signifiant que les prédictions du modèle peuvent être loin des valeurs réelles, indiquant une grande variance dans les erreurs de prédiction. En résumé, bien que le modèle explique bien la variance de la variable cible, les prédictions individuelles présentent des erreurs importantes, suggérant que des améliorations peuvent être apportées pour réduire la variance des erreurs de prédiction. Enfin, la variable qui explique quasiment 80% de nos prédictions est, sans surprise, market_value_eur. Cela est assez cohérent puisque c'est une estimation de celle-ci. Malheureusement, dans notre étude, c'est assez dommageable car elle prend une part trop importante dans le modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='xg-boost'></a>\n",
    "### <u>c. Modèle final : XGBoost</u>\n",
    "\n",
    "Le dernier modèle que nous avons tenté d'utiliser et le modèle XGBoost de la bibiliothèque XGBRegressor. C'est un algorithme de machine learning basé sur les arbres de décision, conçu pour optimiser la vitesse et les performances des modèles de gradient boosting. Il utilise des techniques avancées comme la régularisation pour prévenir le surapprentissage et le traitement parallèle pour accélérer l'entraînement. Il est beaucoup utilisé notamment dans les hackathons de machine learning car, en théorie, précis et robuste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from using_data.ml_models import xgboost_regression as xgb\n",
    "from using_data.ml_models import plot_xgb_feature_importances as xgfi\n",
    "\n",
    "results_xgb = xgb(data_clean.drop('transfer_fee', axis = 1), data_clean['transfer_fee'] , n_estimators= 1000, max_depth= 3)\n",
    "print(\"La racine de l'erreur quadratique moyenne est : \" + str(sqrt(results_xgb['mse_test'])))\n",
    "print('Le r2 est de : ' + str(results_xgb['r2_test']))\n",
    "xgfi(results_xgb['feature_importances'], results_xgb['feature_names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grâce au modèle XGBoost, on améliore le R2 de 0.05, on réduit la racine de l'écart quadratique de quasi 100 000 euros et market_value_eur n'est pas la seule variable importante bien qu'elle prédise quasi 40% de nos résultats. D'autres variables comme le nombre de buts et de passes décisives, l'âge ou encore le temps de jeu permettent de prédire la future valeur d'un joueur.\n",
    "\n",
    "Finalement, le modèle est plus satisfaisant que les précédents, expliquant plutôt bien la variance de nos prédictions. Néanmoins, la variable que nous tentons de prédire a un écart-type de 16 millions, ce qui explique que l'écart quadratique soit si élevé."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='conclusion'></a>\n",
    "## <u>Conclusion</u>\n",
    "\n",
    "Ainsi, ce projet de modélisation statistique de la valeur des joueurs de football a permis d’explorer un enjeu clé dans le sport moderne: l’évaluation des joueurs à partir de données de performances. Grâce à l’intégration de multiples variables provenant de différentes sources telles que des API comme Footballdata.org ou du scraping de plateformes reconnues comme Transfermarkt et FBref, nous avons construit une base de données diversifiée, s'étalant sur 10 années et 7 championnats, essentielle pour une analyse approfondie.\n",
    "\n",
    "Notre approche a permis de mettre en évidence des corrélations, plus ou moins significatives, entre les performances individuelles des joueurs et leur valeur estimée, malgré les biais potentiels des plateformes publiques. Les modèles prédictifs réalisés, notamment la régression linéaire, les Random Forests ainsi que l'utilisation d'XGBoost ont offert des estimations pertinentes, bien que le RMSE soit parfois élevé.\n",
    "\n",
    "En comparant les montants réels des transferts avec les valeurs marchandes de Transfermarkt, nous avons identifié des écarts explicables par des facteurs contextuels tels que l’exposition médiatique (réseaux sociaux notamment) ou le poste des joueurs sur le terrain. Malgré ces écarts, nos analyses ont permis de mieux interpréter les composantes qui influencent la valorisation des joueurs, notamment les performances des joueurs comme le nombre de buts ou de passes décisives. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
